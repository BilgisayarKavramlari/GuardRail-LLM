# GuardRail-LLM: LLM'ler iÃ§in Pratik GÃ¼venlik DuvarÄ± UygulamalarÄ± ğŸ›¡ï¸

> Bu repo, BÃ¼yÃ¼k Dil Modelleri (Large Language Models - LLM) iÃ§in gÃ¼venlik duvarlarÄ± (guardrails) oluÅŸturmanÄ±n Ã¶nemini ve pratiÄŸini gÃ¶stermek amacÄ±yla hazÄ±rlanmÄ±ÅŸ bir koleksiyondur. GÃ¼venilir, gÃ¼venli ve etik sÄ±nÄ±rlar iÃ§inde Ã§alÄ±ÅŸan yapay zeka uygulamalarÄ± geliÅŸtirmek iÃ§in "guardrail" mekanizmalarÄ± kritik bir rol oynar.

Bu proje, **[NVIDIA NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails)** kÃ¼tÃ¼phanesini kullanarak farklÄ± gÃ¼venlik senaryolarÄ± iÃ§in somut ve Ã§alÄ±ÅŸtÄ±rÄ±labilir Ã¶rnekler sunar. Her bir klasÃ¶r, belirli bir gÃ¼venlik sorununa odaklanÄ±r ve bu sorunu nasÄ±l ele alabileceÄŸinizi gÃ¶steren bir uygulama iÃ§erir.

## ğŸ¯ Projenin AmacÄ±

BÃ¼yÃ¼k Dil Modelleri, inanÄ±lmaz yeteneklere sahip olsalar da kontrolsÃ¼z bÄ±rakÄ±ldÄ±klarÄ±nda istenmeyen davranÄ±ÅŸlar sergileyebilirler. Bu proje, aÅŸaÄŸÄ±daki gibi yaygÄ±n sorunlarÄ± kontrol altÄ±na almak iÃ§in programatik Ã§Ã¶zÃ¼mler sunmayÄ± hedefler:

-   **Konu DÄ±ÅŸÄ±na Ã‡Ä±kma:** Modelin belirlenen alanÄ±n dÄ±ÅŸÄ±ndaki sorulara cevap vermesini engelleme.
-   **KiÅŸisel ve Hassas Veri Ä°ÅŸleme:** KullanÄ±cÄ±larÄ±n kiÅŸisel bilgilerini (`PII`) paylaÅŸmasÄ±nÄ± veya modelin bu tÃ¼r bilgileri iÅŸlemesini Ã¶nleme.
-   **Prompt Injection SaldÄ±rÄ±larÄ±:** KÃ¶tÃ¼ niyetli kullanÄ±cÄ±larÄ±n, modelin temel sistem komutlarÄ±nÄ± manipÃ¼le etmesini engelleme.
-   **Toksik ve ZararlÄ± Dil KullanÄ±mÄ±:** Hem kullanÄ±cÄ±nÄ±n girdisindeki hem de modelin Ã§Ä±ktÄ±sÄ±ndaki zararlÄ± dil kullanÄ±mÄ±nÄ± tespit edip engelleme.

## ğŸ› ï¸ KullanÄ±lan Teknolojiler

-   **[NVIDIA NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails):** LLM'ler iÃ§in programlanabilir, denetlenebilir ve kontrol edilebilir gÃ¼venlik duvarlarÄ± eklemek iÃ§in kullanÄ±lan ana aÃ§Ä±k kaynak kÃ¼tÃ¼phane.
-   **[LangChain](https://www.langchain.com/):** LLM uygulamalarÄ± geliÅŸtirmeyi basitleÅŸtiren bir framework.
-   **[Hugging Face Modelleri](https://huggingface.co/):** Temel dil modeli olarak `flan-t5` modeli kullanÄ±lmÄ±ÅŸtÄ±r.

## ğŸ“‚ Proje YapÄ±sÄ±

Proje, her biri farklÄ± bir gÃ¼venlik duvarÄ± konseptini ele alan modÃ¼ler bir yapÄ±da tasarlanmÄ±ÅŸtÄ±r. Her bir modÃ¼l kendi klasÃ¶rÃ¼nde yer alÄ±r ve kendi `config` ve `app.py` dosyalarÄ±nÄ± iÃ§erir.

- `Uygulama 1 : Anonymizer`
  - _Temel bir anonimleÅŸtirme sÃ¼recini iÃ§erir._
- `Uygulama 2 : Anonymizer Ä°leri`
  - _Ä°leri AnonimleÅŸtirme tekniklerini iÃ§erir._
- `Uygulama 3 : Konu KontrolÃ¼`
  - _Embedding kullanÄ±larak bir iÃ§eriÄŸin uygunluÄŸu kontrol edilir._
- `Uygulama 4 : GuardRails GiriÅŸ`
  - _Temel bir akÄ±ÅŸ ve guardrails Ã§alÄ±ÅŸma mantÄ±ÄŸÄ± sunar._
- `Uygulama 5 : SaÄŸlÄ±k UygulamasÄ±`
  - _GeliÅŸmiÅŸ bir uygulama Ã¶rneÄŸi olarak saÄŸlÄ±k alanÄ±ndaki vaka Ã¶rneklerini iÃ§erir._
- `Uygulama 6 : Ä°nsan KaynaklarÄ± ve KiÅŸisel Veriler`
  - _GeliÅŸmiÅŸ bir uygulama Ã¶rneÄŸi olarak insan kaynaklarÄ± alanÄ±ndaki vaka Ã¶rneklerini iÃ§erir._
- `Uygulama 7 : Ä°Ã§erik Ãœretimim`
  - _GeliÅŸmiÅŸ bir uygulama Ã¶rneÄŸi olarak iÃ§erik Ã¼retimi sÄ±rasÄ±ndaki potansiyel tehditlere yÃ¶nelik vaka Ã¶rneklerini iÃ§erir._
- `Uygulama 8 : RAG ile birlikte kullanÄ±m`
  - _Bir LLM projesinde RAG (Retrieval Augmented Genration ) ile birlikte GuardRails yapÄ±sÄ±nÄ±n nasÄ±l kullanÄ±labileceÄŸini gÃ¶stermektedir._

## ğŸš€ Kurulum ve BaÅŸlangÄ±Ã§

Projeyi yerel makinenizde Ã§alÄ±ÅŸtÄ±rmak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlarÄ± izleyin.

1.  **Projeyi KlonlayÄ±n:**
    ```bash
    git clone [https://github.com/BilgisayarKavramlari/GuardRail-LLM.git](https://github.com/BilgisayarKavramlari/GuardRail-LLM.git)
    cd GuardRail-LLM
    ```

2.  **Sanal Ortam OluÅŸturun (Ã–nerilir):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # Windows iÃ§in: venv\Scripts\activate
    ```

3.  **Gerekli KÃ¼tÃ¼phaneleri YÃ¼kleyin:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **ModÃ¼llerin Ã‡alÄ±ÅŸtÄ±rÄ±lmasÄ±:**
    Hemen her proje klasÃ¶rÃ¼nde tek bir app.py dosyasÄ± oluÅŸturulmaya Ã§alÄ±ÅŸÄ±ldÄ±. Dizine girince bu dosyayÄ± Ã§alÄ±ÅŸtÄ±rmanÄ±z durumunda uygulama Ã§alÄ±ÅŸacaktÄ±r. 

    ```powershell
    python app.py
    ```

## Proje YapÄ±sÄ±
<pre>
GuardRail-LLM/
â”œâ”€ uygulama1_anonymizer/
â”œâ”€ uygulama2_anonymizer_ileri/
â”œâ”€ uygulama3_embedding_gruplama/
â”œâ”€ uygulama4_guardrail_ai/
â”œâ”€ uygulama5_saglik_guardrail/
â”œâ”€ uygulama6_IK/
â”œâ”€ uygulama7_Icerik/
â”œâ”€ uygulama8_RAG/
â”œâ”€ requirements.txt
â””â”€ README.md
</pre>

* uygulama1_anonymizer: Temel PII/PHI tespiti ve anonimleÅŸtirme (Ã¶r. Presidio).

* uygulama2_anonymizer_ileri: GeliÅŸmiÅŸ anonimleÅŸtirme ve maskeleme stratejileri.

* uygulama3_embedding_gruplama: Embedding Ã¼retimi ve kÃ¼melenmesi/gruplamasÄ± (vektÃ¶r-tabanlÄ± yaklaÅŸÄ±m).

* uygulama4_guardrail_ai: Guardrails AI / NeMo Guardrails ile I/O korumalarÄ±.

* uygulama5_saglik_guardrail: SaÄŸlÄ±k alanÄ±na Ã¶zel guardrail Ã¶rnekleri (uyarÄ±lar, danÄ±ÅŸ yÃ¶nlendirmesi vb.).

* uygulama6_IK: Ä°K (HR) senaryolarÄ±nda gÃ¼venli Ã¼retim.

* uygulama7_Icerik: Ä°Ã§erik denetimi / moderasyon Ã¶rnekleri.

* uygulama8_RAG: RAG (Retrieval-Augmented Generation) ile guardrail entegrasyonu.

YukarÄ±daki kÄ±sa aÃ§Ä±klamalar klasÃ¶r adlarÄ±na dayalÄ± Ã¶zetlerdir; ayrÄ±ntÄ± ve Ã§alÄ±ÅŸtÄ±rma adÄ±mlarÄ± iÃ§in ilgili alt uygulamanÄ±n READMEâ€™sine bakÄ±nÄ±z.

## Alt Uygulamalar

AÅŸaÄŸÄ±daki baÄŸlantÄ±lar her alt klasÃ¶re ve (varsa) kendi `README.md` dosyalarÄ±na yÃ¶nlendirir:

- **Uygulama 1 â€“ Anonymizer (Temel)**
  - KlasÃ¶r: [`./uygulama1_anonymizer/`](./uygulama1_anonymizer/)
  - README: [`./uygulama1_anonymizer/README.md`](./uygulama1_anonymizer/README.md)

- **Uygulama 2 â€“ Anonymizer (Ä°leri)**
  - KlasÃ¶r: [`./uygulama2_anonymizer_ileri/`](./uygulama2_anonymizer_ileri/)
  - README: [`./uygulama2_anonymizer_ileri/README.md`](./uygulama2_anonymizer_ileri/README.md)

- **Uygulama 3 â€“ Embedding Gruplama**
  - KlasÃ¶r: [`./uygulama3_embedding_gruplama/`](./uygulama3_embedding_gruplama/)
  - README: [`./uygulama3_embedding_gruplama/README.md`](./uygulama3_embedding_gruplama/README.md)

- **Uygulama 4 â€“ Guardrail AI / NeMo Guardrails Entegrasyonu**
  - KlasÃ¶r: [`./uygulama4_guardrail_ai/`](./uygulama4_guardrail_ai/)
  - README: [`./uygulama4_guardrail_ai/README.md`](./uygulama4_guardrail_ai/README.md)

- **Uygulama 5 â€“ SaÄŸlÄ±k Guardrail**
  - KlasÃ¶r: [`./uygulama5_saglik_guardrail/`](./uygulama5_saglik_guardrail/)
  - 1. Ã–rnek Ana AkÄ±ÅŸ : README: [`./uygulama5_saglik_guardrail/README.md`](./uygulama5_saglik_guardrail/README.md)
  - 2. Ã–rnek (TEST SenaryolarÄ±) README: [`./uygulama5_saglik_guardrail/README_test.md`](./uygulama5_saglik_guardrail/README_test.md)

- **Uygulama 6 â€“ Ä°K (HR) SenaryolarÄ±**
  - KlasÃ¶r: [`./uygulama6_IK/`](./uygulama6_IK/)
  - README: [`./uygulama6_IK/README.md`](./uygulama6_IK/README.md)

- **Uygulama 7 â€“ Ä°Ã§erik/Moderasyon**
  - KlasÃ¶r: [`./uygulama7_Icerik/`](./uygulama7_Icerik/)
  - README: [`./uygulama7_Icerik/README.md`](./uygulama7_Icerik/README.md)

- **Uygulama 8 â€“ RAG (Retrieval-Augmented Generation)**
  - KlasÃ¶r: [`./uygulama8_RAG/`](./uygulama8_RAG/)
  - README: [`./uygulama8_RAG/README.md`](./uygulama8_RAG/README.md)

> Not: Bir alt uygulamada `README.md` henÃ¼z yoksa, Ã§alÄ±ÅŸtÄ±rma talimatlarÄ± doÄŸrudan klasÃ¶r iÃ§indeki dosyalarda yer alÄ±yor olabilir.


## Guardrail TÃ¼rlerine KÄ±sa BakÄ±ÅŸ
* Kural TabanlÄ± (Rule-Based): Regex, anahtar kelime listeleri, ÅŸablonlar.
ArtÄ±: HÄ±zlÄ±, yorumlanabilir. Eksi: BaÄŸlamÄ± kavramasÄ± sÄ±nÄ±rlÄ± (kÄ±rÄ±lganlÄ±k).

* Model TabanlÄ± (Model-Based): OdaklÄ± sÄ±nÄ±flandÄ±rma/algÄ±lama modelleri (toksisite, PII/PHI, jailbreak vb.) ile giriÅŸ/Ã§Ä±kÄ±ÅŸ denetimi.
ArtÄ±: BaÄŸlam duyarlÄ±. Eksi: Ek gecikme ve maliyet.

* VektÃ¶r/Embedding TabanlÄ±: Semantik benzerlik ile konu/alan dÄ±ÅŸÄ±na Ã§Ä±kÄ±ÅŸÄ± engelleme (Ã¶rn. cosine similarity).
ArtÄ±: Konu/niyet yakÄ±nlÄ±ÄŸÄ±nÄ± yakalar. Eksi: Ä°nce ayrÄ±mlarda kaÃ§Ä±rma.

* Åema/Gramer ZorlamasÄ± (Structured/Constrained Output): JSON Schema/CFG ile biÃ§imsel geÃ§erlilik garantisi.
ArtÄ±: â€œDaima geÃ§erli JSONâ€ vb. Eksi: Ä°Ã§eriksel doÄŸruluÄŸu tek baÅŸÄ±na garanti etmez.

* Decoding-Time GÃ¼venlik (Safety-Aware Decoding): Ãœretim sÄ±rasÄ±nda gÃ¼venlik/Ã¶dÃ¼l modelleriyle token uzayÄ±nÄ± filtreleme.
ArtÄ±: Ä°nference-time yÃ¶nlendirme. Eksi: Gecikme artÄ±ÅŸÄ±.

* Prompt GÃ¼venliÄŸi & Enjeksiyon SavunmasÄ±: Enjeksiyon/jailbreak tespiti, gÃ¼venilmeyen iÃ§eriÄŸin izolasyonu.
ArtÄ±: Ajan/araÃ§ Ã§aÄŸÄ±rma senaryolarÄ±nda kritik. Eksi: SÃ¼rekli bakÄ±m gerekir.

* DLP/PII/PHI KorumasÄ±: Girdi/Ã§Ä±ktÄ±da kiÅŸisel/saÄŸlÄ±k verilerinin tespiti ve anonimleÅŸtirilmesi.
ArtÄ±: Uyumluluk ve veri sÄ±zÄ±ntÄ± riskinin dÃ¼ÅŸÃ¼rÃ¼lmesi. Eksi: Dil/alan Ã¶zelleÅŸtirmesi gerekebilir.

* HITL & Politika-olarak-Kod: DÃ¼ÅŸÃ¼k gÃ¼ven-yÃ¼ksek risk durumlarÄ±nda insan devri; RBAC/ABAC ile eylem dÃ¼zeyinde yetkilendirme.
ArtÄ±: Denetlenebilirlik. Eksi: Operasyonel yÃ¼k.

Bu desenlerin birden fazlasÄ±nÄ± birlikte kullanarak savunma-iÃ§i-savunma (defense-in-depth) mimarisi Ã¶nerilir.